---
title: "Levantamento de processos sobre educação no TJSP"
author: "Associação Brasileira de Jurimetria"
date: "`r format(Sys.Date(), '%d de %B de %Y')`"
linkcolor: "blue"
geometry: bmargin=1.5in,lmargin=.8in,rmargin=.8in,tmargin=.7in
---

```{r}
setwd('../data-raw/')
```

```{r echo=FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      echo = FALSE)
```

```{r}
library(tidyverse)
library(stringr)
library(forcats)
library(esaj)
library(tjsp)
```

# Introdução

O presente estudo tem como objetivo avaliar a viabilidade de analisar processos sobre o tema "educação" usando como base os processos judiciais disponíveis na ferramenta de pesquisa "Consulta de Julgados de Primeiro Grau" do TJSP. A principal dúvida é se o volume de casos que correm em Segredo de Justiça é negligenciável ou não.

Para isso, fizemos o levantamento do volume de sentenças do TJSP por assunto e por ano, com base nos assuntos descritos na Tabelas Processuais Unificadas (TPUs, Res. 46 CNJ). Os números foram comparados com dados do Relatório "A Qualidade Social da Educação Brasileira nos Referenciais de Compromisso do Plano e do Sistema Nacional de Educação" (PROJETO 914BRZ1009.2 CNE/UNESCO), aqui denominado "relatório".

# Metodologia

O primeiro passo do estudo foi levantar a lista de assuntos na página do TJSP. Em seguida, cruzamos os dados com uma lista construída no relatório (pags 81 e 82). A lista contém 22 códigos de assuntos distintos, dos quais 2 são pastas de assuntos (10051 - Ensino Fundamental e Médio e 10029 - Ensino Superior).

Da lista de 22 assuntos, apenas 8 foram encontrados na lista do TJSP. No entanto, 12 dos 14 casos não encontrados eram especificações das pastas de assuntos supracitadas. Os outros casos que não bateram foram "12006 - Evasão Escolar" e "11998 - Matrícula e frequência obrigatória em escola oficial de ensino fundamental".

```{r}
# assuntos <- cjpg_tabs('assunto')
# write_rds(assuntos, 'assuntos.rds')
assuntos <- read_rds('assuntos.rds')
leafs <- c(
  '10062', '10063', '10058', '10055', '10059', '10054', '10053',
  '10052', '10060', '10056', '10057', '10061',
  '10051', '10029',
  '10377', '10380',
  '9966', '12006',
  '11998', '7620',
  '6077', '6037'
) %>% 
  enframe() %>% 
  set_names(c('id', 'cod_leaf')) %>% 
  inner_join(assuntos, 'cod_leaf') %>%
  with(cod_leaf)
  
```

O segundo passo do levantamento foi realizar uma pesquisa no site do TJSP para cada ano e cada assunto obtido. Isso foi feito de forma automatizada a partir da utilização de rotinas computacionais desenvolvidas pela ABJ, utilizando-se o software estatístico R. O código-fonte utilizado para essa pesquisa e os dados obtidos estão diponíveis [nesse link](https://github.com/abjur/educacaoTJSP).

```{r eval=FALSE}
s <- cjpg_session()
tots <- tibble(leaf = leafs, ano = list(2009:2016)) %>% 
  unnest(ano) %>% 
  arrange(leaf, ano) %>% 
  group_by(leaf, ano) %>%
  do(ntot = {
    parms <- cjpg_parms(s, assuntos = .$leaf,
                        data_inicial = sprintf('%d-01-01', .$ano),
                        data_final = sprintf('%d-12-31', .$ano))
    npags <- cjpg_npags(s, parms)
    if (!is.na(npags)) {
      cjpg(s, parms, 
         path = sprintf('processos/%s_%s', .$ano, .$leaf), 
         max_pag = Inf)
    } else {
      tibble::tibble(result = '0 resultados') 
    }
  }) %>% 
  ungroup() %>% 
  unnest(ntot)

tots_tidy <- tots %>% 
  inner_join(assuntos, c('leaf' = 'cod_leaf')) %>%
  replace_na(list(ntot = 0.0))

write_rds(tots_tidy, 'tots_tidy.rds')

# n_arqs <- 'processos' %>% 
#   dir(full.names = TRUE) %>% 
#   tibble::enframe() %>% 
#   select(pasta = value) %>% 
#   mutate(p2 = basename(pasta)) %>% 
#   separate(p2, c('ano', 'leaf')) %>% 
#   mutate(ano = as.integer(ano)) %>% 
#   mutate(n_arq = map_int(pasta, ~length(dir(.x))))
# n_tidy <- read_rds('tots_tidy.rds') %>% 
#   select(leaf, ano, ntot)
# n_arqs %>% 
#   inner_join(n_tidy, c('leaf', 'ano')) %>% 
#   filter(ntot != n_arq)

```

# Resultados

A Tabela \@ref(tab:tabtot) mostra o volume de sentenças encontrado para cada assunto e cada ano no TJSP, a partir de 2009. Observe que o volume de sentenças só passou a ser relevante a partir de 2012. O volume total de sentenças encontrado foi `r sum(tots_tidy$ntot)`.

```{r tabtot}
tots_tidy <- read_rds('tots_tidy.rds')
tots_tidy %>% 
  select(leaf, titulo_leaf, ano, ntot) %>% 
  mutate(titulo_leaf = str_trunc(titulo_leaf, 40)) %>% 
  group_by(leaf, titulo_leaf) %>% 
  mutate(total = sum(ntot)) %>% 
  ungroup() %>% 
  arrange(ano) %>% 
  spread(ano, ntot) %>% 
  arrange(desc(total)) %>% 
  select(leaf, titulo_leaf, starts_with('2'), total) %>% 
  unite(ll, leaf, titulo_leaf, sep = '@') %>% 
  janitor::add_totals_row() %>% 
  separate(ll, c('cod', 'assunto'), sep = '@', fill = 'left') %>% 
  replace_na(list(cod = '')) %>% 
  knitr::kable(caption = 'Volume de sentenças por ano e assunto.',
               booktabs = TRUE)
```

A Figura \@ref(fig:figtot) mostra a mesma informação, mas de forma gráfica. É possível notar que o volume de sentenças atingiu o pico em 2014 e vem caindo em 2015 e 2016 (como 2016 ainda não acabou, essa comparação pode ser inadequada). O assunto com maior volume processual é "Estabelecimentos de Ensino", seguido por "Ensino fundamental e médio".

```{r figtot, fig.width=10, fig.cap='Volume de sentenças por ano e assunto.'}
tots_tidy %>% 
  mutate(assunto = str_wrap(titulo_leaf, 30)) %>% 
  mutate(assunto = fct_reorder(assunto, ntot, sum, .desc = TRUE)) %>%
  ggplot(aes(x = ano, y = ntot, colour = assunto)) + 
  geom_line() +
  theme_bw(15) +
  scale_x_continuous(breaks = 2009:2016) +
  xlab('Ano') +
  ylab('Volume de sentenças')

m <- tots_tidy %>% 
  group_by(ano) %>% 
  summarise(tot = sum(ntot)) %>% 
  summarise(m = mean(tot)) %>% 
  with(m) %>% 
  round()
```

Com base nesse levantamento, constatamos que a média anual de `r m` sentenças é significativamente menor que o apresentado no relatório, com média de 6165 casos ao ano. A segunda média foi calculada a partir do volume observado na tabela da página 85 do relatório, considerando os anos de 2009 e 2014. Não conseguimos identificar no relatório se o volume apresentado se referia ao estoque de processos ativos, ao volume de processos distribuídos ou decisões. Supondo que essas médias sejam comparáveis, os resultados indicam que estudos sobre esse tema precisam ser realizados a partir da elaboração de ofícios para extração de dados para o TJSP, para que os dados em segredo possam ser obtidos diretamente do sistema.

# Próximos passos

Para avaliar o efeito da medida tomada em 2012/2013 no volume de processos, é necessário realizar um estudo prospectivo, isto é, estudar o volume de processos distribuídos por ano e não o volume de sentenças. Atualmente, existem três formas diferentes de listar processos judiciais em estudos prospectivos. O primeiro envolve a composição de ofícios para obtenção de dados diretamente dos tribunais. O segundo envolve a obtenção de listas de processos nos Diários de Justiça Eletrônicos (DJEs). Finalmente, o terceiro envolve a amostragem de números de processos. Nesse caso, como há necessidade de obter informações do conteúdo de processos que correm em segredo de justiça, a composição de ofícios é a única alternativa viável.

Outra investigação necessária envolve o fenômeno da classificação genérica de assuntos. Infelizmente, muitos processos são classificados com assuntos das pastas ao invés das informações mais específicas sobre o caso. Assim, pode ser que existam mais ações no judiciário do que os casos identificados no presente levantamento. A ABJ já utilizou métodos estatísticos no passado que buscam resolver parcialmente esse problema.

O próximo passo para essa pesquisa consiste em acessar os textos das sentenças e/ou petições iniciais/liminares de vários processos e desenvolver um robô capaz de classificar os processos em categorias mais informativas que as TPUs. Essa classificação pode ser feita de forma supervisionada (através da pré-classificação de alguns textos em categorias adequadas) ou não supervisionada (agrupamento de textos em grupos que serão posteriormente interpretados).

-------------------------------------------------------------------------------

## Continuação

Análise dos textos

```{r eval=F}
s <- cjpg_session()
tots <- tibble(leaf = leafs, ano = list(2009:2016)) %>% 
  unnest(ano) %>% 
  arrange(leaf, ano) %>% 
  group_by(leaf, ano) %>%
  do(ntot = {
    parms <- cjpg_parms(s, assuntos = .$leaf,
                        data_inicial = sprintf('%d-01-01', .$ano),
                        data_final = sprintf('%d-12-31', .$ano))
    npags <- cjpg_npags(s, parms)
    if (!is.na(npags)) {
      cjpg(s, parms, 
         path = sprintf('processos/%s_%s', .$ano, .$leaf), 
         max_pag = Inf)
    } else {
      tibble::tibble(result = '0 resultados') 
    }
  }) %>% 
  ungroup() %>% 
  unnest(ntot)
```

```{r}
arqs <- dir('processos', full.names = TRUE, recursive = TRUE)
d_tjsp <- parse_cjpg(arqs)
saveRDS(d_tjsp, 'd_tjsp_educ.rds')

View(d_tjsp)

d_tjsp <- readRDS('d_tjsp_educ.rds')

d_tidy <- d_tjsp %>% 
  filter(!is.na(txt), !is.na(classe), !is.na(assunto)) %>% 
  select(n_processo, classe, assunto,
         comarca, dt_disp = data_de_disponibilizacao,
         foro, magistrado, vara, sentenca = txt) %>% 
  arrange(desc(lubridate::dmy(dt_disp))) %>% 
  distinct(n_processo, .keep_all = TRUE)

set.seed(20170328)
d_tidy %>% 
  sample_n(200) %>% 
  openxlsx::write.xlsx('amostra.xlsx')

set.seed(20170328)
d_tidy %>% 
  sample_n(200) %>% 
  with(walk2(n_processo, sentenca, ~{
    arq <- paste0('sentencas/', .x, '.txt')
    cat(.y, file = arq)
    rmarkdown::render(input = arq, 
                      output_format = rmarkdown::word_document(),
                      quiet = TRUE)
    file.remove(arq)
  }))

system('pandoc sentencas/00002142520168260650.txt sentencas/00002142520168260650.docx')  


r_tags <- c('creche|vaga', 'escola', 
            'professor', 'divida|debito',
            'acordo|homolog|concili', 'seguranca')
pegar_tags <- function(txt) {
  map_df(r_tags, ~tibble::tibble(tag = .x, n = sum(str_detect(txt, .x))))
}

res <- d_tidy %>% 
  mutate(sentenca = tolower(abjutils::rm_accent(sentenca))) %>% 
  group_by(assunto) %>% 
  do(pegar_tags(.$sentenca)) %>% 
  ungroup() %>% 
  spread(tag, n)

tab <- res %>% 
  inner_join(count(d_tidy, assunto), 'assunto') %>% 
  mutate_at(vars(-assunto, -n), 
            funs(sprintf('%d (%s)', ., scales::percent(./n)))) %>% 
  mutate(assunto = str_trunc(assunto, 30)) %>% 
  arrange(desc(n)) %>% 
  rename(Total = n) %>% 
  knitr::kable()

'd_tjsp_educ.rds' %>% 
  readRDS() %>% 
  saveRDS('d_tjsp_educ2.rds', compress = 'bzip2')

```

```{r}
assuntos_new <- c('9985', '10370', '10028', '10051', '10029', '9633',
                  '9964', '11818', '1156', '14', '6031', '6071', '6033', 
                  '6039', '10062', '10063', '10058',
                  '10055', '10059', '10054', '10053', '10052', '10060', 
                  '10056', '10057', '10061', '10051',
                  '10029', '10377', '10380', '9966', '12006', '11998', 
                  '7620', '6077', '6037') %>% 
  enframe() %>% 
  set_names(c('id', 'cod_leaf')) %>% 
  inner_join(assuntos, 'cod_leaf') %>%
  with(cod_leaf)
setdiff(assuntos_newa)

```

```{r}
d_educ <- 'd_tjsp_educ.rds' %>% 
  readRDS()
```

```{r}
d_tidy

```

